{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbffb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0acf53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model architecture\n",
    "trained_vgg_model = models.vgg16()\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "trained_vgg_model.classifier[-1] = nn.Linear(trained_vgg_model.classifier[-1].in_features, num_classes)\n",
    "\n",
    "\n",
    "# Load the saved weights into the model\n",
    "trained_vgg_model.load_state_dict(torch.load(\"../data/trained_vgg_model.pt\"))\n",
    "\n",
    "trained_vgg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36bf9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, pruning_rate):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_rate)\n",
    "            prune.remove(module, 'weight')  # Make the pruning permanent\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d08b5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_rate = 0.3  # Define the pruning rate (e.g., 0.2 means pruning 20% of the weights)\n",
    "pruned_vgg_model = prune_model(trained_vgg_model, pruning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef9610b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_vgg_model.state_dict(), \"../data/trained_vgg_model_pruned.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92ebfacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test accuracy and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce86ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9661be3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model architecture\n",
    "trained_vgg_model = models.vgg16()\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "trained_vgg_model.classifier[-1] = nn.Linear(trained_vgg_model.classifier[-1].in_features, num_classes)\n",
    "\n",
    "\n",
    "# Load the saved weights into the model\n",
    "trained_vgg_model.load_state_dict(torch.load(\"../data/trained_vgg_model.pt\"))\n",
    "\n",
    "trained_vgg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d88ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da5ffda4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output shape: torch.Size([1, 10])\n",
      "Quantized output shape: torch.Size([1, 10])\n",
      "Max absolute error: tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Define the input data shape (batch size, channels, height, width)\n",
    "input_shape = (1, 3, 224, 224)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(input_shape)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_vgg_model = torch.quantization.quantize_dynamic(\n",
    "    trained_vgg_model, {torch.nn.Conv2d}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Run inference on the original model\n",
    "with torch.no_grad():\n",
    "    output = trained_vgg_model(input_data)\n",
    "\n",
    "# Run inference on the quantized model\n",
    "with torch.no_grad():\n",
    "    quantized_output = quantized_vgg_model(input_data)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Original output shape:\", output.shape)\n",
    "print(\"Quantized output shape:\", quantized_output.shape)\n",
    "print(\"Max absolute error:\", torch.max(torch.abs(output - quantized_output)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6a96b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_vgg_model.state_dict(), \"../data/trained_vgg_model_quantized.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1f70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6967e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7663052",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn((100, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53d98cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.58 s ± 172 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trained_vgg_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16625f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.43 s ± 233 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pruned_vgg_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "871efdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.39 s ± 174 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit quantized_vgg_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61849eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f44832a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VGG model memory usage: 512.32 MB\n",
      "Pruned VGG model memory usage: 512.32 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_model_memory_usage(model):\n",
    "    total_memory = 0\n",
    "    for param in model.parameters():\n",
    "        param_memory = param.data.numel() * param.data.element_size()\n",
    "        total_memory += param_memory\n",
    "    return total_memory/1048576\n",
    "\n",
    "trained_vgg_memory = get_model_memory_usage(trained_vgg_model)\n",
    "pruned_vgg_memory = get_model_memory_usage(pruned_vgg_model)\n",
    "quantized_vgg_memory = get_model_memory_usage(quantized_vgg_model)\n",
    "\n",
    "print(f\"Original VGG model memory usage: {trained_vgg_memory:.2f} MB\")\n",
    "print(f\"Pruned VGG model memory usage: {pruned_vgg_memory:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba1f68ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized VGG model memory usage: 128.12 MB\n"
     ]
    }
   ],
   "source": [
    "def get_quantized_model_memory_usage(model):\n",
    "    total_memory = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        param_memory = 0\n",
    "        if \"weight\" in name and hasattr(param, \"q_per_channel_scales\"):\n",
    "            # Quantized parameter\n",
    "            quantized_bits = 8  # Assuming qint8 quantization\n",
    "            param_memory = param.data.numel() * (quantized_bits // 8)\n",
    "        else:\n",
    "            # Non-quantized parameter\n",
    "            param_memory = param.data.numel() * param.data.element_size()\n",
    "        total_memory += param_memory\n",
    "    return total_memory/1048576\n",
    "\n",
    "quantized_vgg_memory = get_quantized_model_memory_usage(quantized_vgg_model)\n",
    "\n",
    "print(f\"Quantized VGG model memory usage: {quantized_vgg_memory:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77cd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90f992da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VGG model sparsity: 0.00%\n",
      "Pruned VGG model sparsity: 3.29%\n"
     ]
    }
   ],
   "source": [
    "def check_sparsity(model):\n",
    "    total_elements = 0\n",
    "    zero_elements = 0\n",
    "    for param in model.parameters():\n",
    "        total_elements += param.numel()\n",
    "        zero_elements += (param == 0).sum().item()\n",
    "    sparsity = zero_elements / total_elements * 100\n",
    "    return sparsity\n",
    "\n",
    "trained_vgg_sparsity = check_sparsity(trained_vgg_model)\n",
    "pruned_vgg_sparsity = check_sparsity(pruned_vgg_model)\n",
    "\n",
    "print(f\"Original VGG model sparsity: {trained_vgg_sparsity:.2f}%\")\n",
    "print(f\"Pruned VGG model sparsity: {pruned_vgg_sparsity:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443f0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd62179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2b92561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /opt/homebrew/lib/python3.10/site-packages (5.9.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9279bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VGG model memory usage during inference: 797.140625 MB\n",
      "Pruned VGG model memory usage during inference: 529.875 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss\n",
    "\n",
    "# Create input tensor\n",
    "input_data = torch.randn((1, 3, 224, 224))\n",
    "\n",
    "# Measure memory usage before inference\n",
    "before_memory_usage = memory_usage()\n",
    "\n",
    "# Run inference on the original model\n",
    "with torch.no_grad():\n",
    "    output = trained_vgg_model(input_data)\n",
    "\n",
    "# Measure memory usage after inference\n",
    "after_memory_usage = memory_usage()\n",
    "\n",
    "print(f\"Original VGG model memory usage during inference: {(after_memory_usage - before_memory_usage)/1048576} MB\")\n",
    "\n",
    "# Measure memory usage before inference\n",
    "before_memory_usage_pruned = memory_usage()\n",
    "\n",
    "# Run inference on the pruned model\n",
    "with torch.no_grad():\n",
    "    pruned_output = pruned_vgg_model(input_data)\n",
    "\n",
    "# Measure memory usage after inference\n",
    "after_memory_usage_pruned = memory_usage()\n",
    "\n",
    "print(f\"Pruned VGG model memory usage during inference: {(after_memory_usage_pruned - before_memory_usage_pruned)/1048576} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16a509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8cb8973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "trained_vgg_model.eval()\n",
    "\n",
    "# Define an example input tensor\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the model to ONNX format\n",
    "torch.onnx.export(trained_vgg_model, dummy_input, \"../data/vgg.onnx\", export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536e4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b29d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca64649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.files.get('image'):\n",
    "        image = Image.open(request.files['image'].stream).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = vgg11_model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        class_id = int(predicted.item())\n",
    "        return jsonify({'class_id': class_id})\n",
    "\n",
    "    return jsonify({'error': 'No image provided'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
